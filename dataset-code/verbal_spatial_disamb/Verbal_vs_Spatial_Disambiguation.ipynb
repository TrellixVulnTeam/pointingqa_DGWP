{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from visual_genome import api as vg\n",
    "import visual_genome.utils as utils\n",
    "from PIL import Image as PIL_Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import ujson\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Verbal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"VisualGenomeVerbal.json\")\n",
    "verbal = ujson.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load objects\n",
    "file = open(\"objects.json\")\n",
    "objs = ujson.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load objects\n",
    "file = open(\"attributes.json\")\n",
    "attrb = ujson.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in attrb:\n",
    "    imgID = img['image_id']\n",
    "    objects[imgID] = {}\n",
    "    for o in img['attributes']:\n",
    "        objectID = o['object_id']\n",
    "        objects[imgID][objectID] = o\n",
    "        del objects[imgID][objectID]['object_id']\n",
    "        \n",
    "    #del objects[imgID]['image_id']\n",
    "    #del objects[imgID]['image_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['teal', 'black red', 'tan-colored', 'navy', 'yellow gold', 'peach', 'ed and white', 'back of blue', 'white with red sauce', 'royal blue', 'white.', 'dark yellow', 'blue with red trim', 'blue floral', 'orange and black', 'bright green', 'marroon', 'cream color', 'three colored', 'mostly green', 'pink frosted', 'blue-grey', 'mustard colored', 'solid dark brown', 'green moss', 'whitish', 'dark gray', 'neon', 'clay colored', 'red brick', 'brown/white', 'olive green', 'brown color', 'bright', 'cobalt blue', 'dark fucshia', 'light colored', 'blue rimmed', 'solid color', 'yellow green', 'copper brown', 'navy blue', 'chocolate-colored', 'pinkl', 'light white', 'medium brown', 'dappled gray', 'blue and grey', 'yellowish green', 'neon yellow', 'brunette', 'light green', 'multicolored', 'darkbrown', 'greenish blue', 'lush green', 'red lettered', 'jet black', 'gourmet', 'black colored', 'multi colored', 'fucshia', 'white and green', 'off-white', 'blue colored', 'clothed black', 'green colored', 'deep dark brown', 'light beige', 'light skinned', 'maroon', 'sheer', 'green and yellow', 'lime green', 'vibrant', 'discolored', 'blackened', 'reddish', 'brown,black', 'brown,black,white', 'dark coloredk', 'grayish', 'reddish brown', 'white+maroon', 'dark colored', 'burgundy', 'bright yellow', 'violet', 'blue and clear', 'yellow and blue', 'black with red sauce', 'are blue', 'dark green', 'orange frosted', 'brown,blue', 'greenish', 'calico', 'creamy', 'shiny blue', 'yellow,brown', 'sky blue', 'gold', 'light tan', 'rainbow colored', 'painted green', 'monochrome', 'taupe', 'cream-colored', 'white red', 'cream colored', 'neon green', 'rainbow', 'white colored', 'red+white', 'pale yellow', 'brown, black and white', 'deep blue', 'brownish', 'blue color', 'baby blue', 'crayon themed', 'grayish-black', 'white and black', 'mint green', 'green grey', 'red and white', 'chrome', 'green', 'white,', 'evergreen', 'yellow', 'white color', 'blue-green', 'lavender', 'yelow', 'different colors', 'dark coloredk', 'goldenrod color', 'yellow and green', 'light-brown', 'bright blue', 'golden', 'gray', 'tan', 'turquoise', 'golds', 'colorful', 'colored', 'red', 'pink', 'purple', 'red-orange', 'light blue', 'white', 'yellow', 'multi-colored', 'aqua', 'grey', 'black and red', 'beige', 'blonde', 'dark', 'dyed', 'light', 'dark blue', 'blue and white', 'orange', 'brown', 'green', 'black', 'blue', 'silver', 'dark brown', 'light brown', 'chestnut colored']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbalColors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for img in verbal: # for each img\n",
    "    imgID = img['id']\n",
    "    for q in img['qas']:\n",
    "        # https://www.geeksforgeeks.org/python-check-substring-present-given-string/\n",
    "        #count += 1\n",
    "        if re.sub(r'[^\\w\\s]', '', q['answer'].lower().strip()) not in colors or q['question'].lower().find('color') != -1: # color question\n",
    "            #print(q['question'])\n",
    "            #print(q['answer'])\n",
    "            count += 1\n",
    "            if str(imgID) not in verbalColors:\n",
    "                verbalColors[str(imgID)] = []\n",
    "                \n",
    "            answer = q['answer']\n",
    "            question = q['question']\n",
    "            qaID = str(q['qa_id'])\n",
    "            answers = set()\n",
    "            for o in q['q_objects']: # for each object for this question\n",
    "                objectID = o['object_id']\n",
    "                if 'attributes' in objects[imgID][objectID]: # attributes of this object\n",
    "                    for a in objects[imgID][objectID]['attributes']:\n",
    "                        if a.lower().strip() in colors:\n",
    "                            answers.add(re.sub(r'[^\\w\\s]', '', a.lower().strip()))\n",
    "            answers = list(answers)\n",
    "            verbalColors[str(imgID)].append({'qa_id': qaID, 'question': question, 'answer': re.sub(r'[^\\w\\s]', '', answer.lower().strip()), 'answers': answers})\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbalColors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to new json file\n",
    "with open(\"verbalColors.json\", \"w\") as outfile: \n",
    "    ujson.dump(verbalColors, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v['38']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbalColors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notColor = ['awaiting hit', 'lightest', ' Two', 'unreadable', 'partially shown', 'dump truck', 'snowboarding', 'holding', 'cabinet', 'far away', 'faraway', 'warehouse', 'marbled', 'aluminum', 'marble', 'waiting', 'runngin', 'reflective', 'textured', 'wrinkled', 'illuminated', 'wadded up', 'clapping', 'upright', 'fully shown', 'puffy', 'barren', 'eating', 'chartreuse', 'yawning', 'picket', 'cooking', 'facing away', 'dark bay', 'shaped', 'held', 'in distance', 'gala', 'saying ox ord st', 'wii', 'saying fully license', 'skateboarding', 'polka dot', 'pullover', 'brick', 'swiss', 'in the sky', 'stop', 'at station', 'off', 'sporty', 'soda', 'texting', 'spirited', 'close', 'potted', 'five', 'ground services', 'half shown', 'storm cloud', 'lying down', 'heavy brown', 'on hill', 'eyed', 'tabsco sauce', 'arabian', 'perched', 'aground', 'pointing down', 'kirtchenaid', 'go pro', 'xbox', 'dsouble decker', 'lit up', 'yan', 'fruit', 'serious', 'three', 'chocolate', 'glowing', 'perry ellis brand', 'an outfielder', 'stj', 'heavy', 'Peach ', 't-shirt', 'butting heads', 'circle shape', 'advertisement', 'caught', 'African', 'crayon designed', 'on the right', 'trotting', 'wood', 'car', 'cute',  'curly', 'patchy', 'forward', 'displayed', 'in the air', 'show planes', 'piled', 'wooly', 'road', 'liquid', 'pizza', 'juice', 'half gallon', 'vanilla', 'wrought', 'clarence hotel', 'in air', 'fighting', 'lit', 'broad', 'advertising construction', 'print', \"wall's\", 'furthest', 'expensive', 'pointed', 'vanner', 'paper', 'pointing', 'muscular', 'playstation', 'laptop', 'dunlop', 'these', 'bold', 'different', 'chained', 'hanging', 'catcher', 'being cooked', 'one way', 'long-sleeved', 'bakery', 'inside', 'staring', 'tanning', 'covered', 'away', 'terrazzo', 'out',  'black rectangle', 'thin', 'shredded', 'bus stop','tranquil', 'weathered', 'exit', 'voluminous', 'hard wood', 'waving', 'galloping', 'cake','taking picture', 'leather', 'wet', 'computer', 'masked', 'stack', 'semi','open','globe', 'labrador', 'moving', 'cardboard','no entry', 'indicating', 'old fashioned', 'largest', 'oak', 'facing', 'houseboat', 'chain link', 'black passenger', 'ad', 'hobart', 'full sized', 'rusty', 'cheese', 'local', 'knitted', 'blocked', 'on', 'colgate', 'bottom', 'winter coated', 'bulky', 'hard', 'fuzzy', 'facing each other', 'boat', 'olive oil', 'fat', 'pair', 'quant', 'interior', 'crayon','in group', 'playing tennis', 'attached','calm','sailboat', 'dirt', 'vinyl record', 'boisterous', 'fully-grown', 'bald', 'wearing', 'lost', 'suede', 'displaed', 'terra cotta', 'vandalized', 'medium', 'in a barn', 'stacked', 'tennis player', 'main', 'odd', 'transparent', 'hard sided', 'opened', 'fluffy', 'lighter', 'baby', 'hung', 'wall clock', 'hawaiian', 'has', 'world history', 'dusty', 'jumping', 'electronic', 'looking left', 'cleaning', 'melted','spare','ski', 'smallest', 'oil', 'baseball player', 'ceramic', 'cub', 'normal', 'drinking water', 'bending forward', 'broken', 'propped', 'pleated', 'tie dye','bathing', 'skinny', 'specked', 'apartments', 'oversized',  'compact', 'two floors', 'domed', 'full', 'performing tricks', 'lipton', 'sleeping', 'parking light', 'on wall', 'in enclosed area', 'stalking', 'bending', 'silky', 'carried', 'lying on side', 'overhead', 'sleek', 'stony', 'hornless', 'here', 'business', 'sliced', 'wading', 'glittered', 'strapless', ' corner', 'wire', 'laying down', 'roman numeral', 'beat down', 'flat', 'american', 'double decker', 'spotify', 'mismatch laced', 'rollerblading', 'fresh', 'plastic', 'fried', 'strange', 'sports', 'taking photo', 'crossing', 'rough', 'two way', 'back sided', 'hexagon shaped', 'protective', 'ahead', 'on a farm', 'steel', 'sailing', 'ready', 'middle', 'wired', 'wild', 'short-sleeved', 'cream', 'not folded out', 'slice', 'plain ','upside down', 'opaque', 'to the side','sleepy', 'no left turn', ' misty', 'for safety', 'bushy', 'laughing', 'concrete', 'statue', 'in Jug', 'walking', 'daffodils', 'smooth', 'stand', 'of child', 'red delicious', 'part of herd', '3-way', 'tooth', 'button-up', 'saying 4 way', 'octangonal', 'very thin', 'multiple', 'protection', 'c-shaped', 'black white', 'bathroom', 'mastercard', 'little', 'bird', 'vintage', 'sparse', 'hub cap', 'gypsy', 'lime', 'mailing', 'wallpapered', 'grouped', 'in barn', 'distant', 'performing stunt','curled', 'stacked up', 'a helmet', 'nike', 'posted', 'leafless', 'square shaped', 'gree', 'tiger striped', 'eating grass', 'pine tree', 'foreground', 'smart car', 'second', 'watching', 'used', 'flipped', 'cement',  'grazing by road', 'stucco', 'mini', 'gopro', 'on rider', 'parked', 'ripening', 'beef', 'designed', 'factory', '3', 'giant', 'chevron pattern', 'flying', 'baclwards', 'tied', 'worn', 'feeding', 'stone', 'closest', 'a man', 'double', 'N 90 ST', 'bent over','in a row', 'long', 'average sized', 'tall', 'similar', 'nintendo', 'stop sign', 'turbulent', 'saying', 'peeling', 'spiral', 'withered', 'foamy', 'street sign', 'power', 'gallon', 'beautiful', 'pick-up truck','creme', 'squre', 'angry', 'pieces', 'roman numerals', 'piebald', 'smaller', 'toasted', 'one', 'dye', 'sideways on', 'clear', 'in tracks', 'stainless steel', 'semi-transparent', 'facing forward', 'convertible', 'seagulls', 'still on skein', 'naked', 'shirt', 'dried', 'ellow', 'crumbles', 'octagon shaped', 'airborne', 'many', 'informational', 'rotten', 'arrangement', 'participating', 'fuck it ship it', 'a boy', 'filled', 'wooden', 'midair', 'bent down', 'lucite/acrylic', 'old', '26  ', 'vertical', 'sitting on chair', 'throw pillow', 'bag', ' dead', 'shaggy', 'circular', 'tilling', 'rolex', 'dark bear', 'denim', 'slim', 'lowest', 'teddy bear', 'dead trunk', 'docked', 'turned-around', 'army truck', 'missing small panes', 'furthest to the left', 'pulling', 'wall', 'on right', 'inflatable', 'billowing', 'chestnut', 'vintage looking', '7', 'history book', 'cooked', 'biggest', 'checked', 'enclosed', 'frosted', 'running left', 'scratched', 'triangular', 'yahoo', 'grass', 'frowning', 'retro looking', 'wrapped', 'partially complete', 'sad', 'woven', 'CLEAR', 'in tree', 'camera man', 'amber', 'powder covered', 'alert', 'bury bolton street', 'bruised', 'on bottom', 'polo', 'turtleneck', 'a baby', 'parking', 'pepperoni', 'gazing', 'in garden', 'chinese restaurant', 'framed', 'triangle', 'petrified', 'big', 'elderly', 'asian', 'zebra', 'metallic', 'visa', 'striped', 'man', 'on left', 'in background', 'native american', 'talking', 'getting ready', 'ripe', 'leaning', 'in a group', 'looking forward', 'right-pointed', 'tank', 'baseball hat', 'arched', 'unglazed', 'grazing ', 'diving', 'storm', 'ridged', 'saying stop', 'handwritten', 'kneeling', 'done', 'faux pearl', 'single', 'plaster', 'a sedan', 'for video game', 'roman numeral II', 'classic', 'no turns', 'parchment', 'showing', 'representing u.s.a.', 'coniferous', 'tented', 'clean', 'parallel', 'grafitti', '4 way', 'portion', 'upholstered', 'facing front', 'fall', 'octagon', 'curvy', 'crowned', 'thick', 'shadowy', 'in foreground', 'bearded', 'wadded-up', 'caution', 'feathered', 'growing', 'large.', 'cheesy', 'in his suit', 'stump', 'small', 'sitting', 'trimmed in white', 'f', 'maybe hand knit', 'unoccupied', 'poodle', 'top', '1', 'weird', 'cured', 'growing on tree', 'old looking', 'flying down', 'far', 'Several ', 'dying', 'history', 'hour', 'shift', 'wadded', 'stands straight ', 'furry', 'sprinkled', 'auric', '5 story', 'pine', 'bitcasa', 'in photo', 'pile', 'bottle shaped', 'set', 'plaid', 'spread', 'paint', 'octaganol', 'spraying', 'six', 'samsung', 'existing', 'toy', 'bending to eat', 'whit', 'turned', 'aparments', 'horizontal', 'porsche', 'brown glass beer', 'chocolate chip', 'short sleeve', 'plate', 'brush', 'racing', 'bus stop sign', 'shrimp', 'a gallon', 'arrow', 'Windows', 'soft', 'chevy', 'street', 'adult', 'finished', 'playing', 'collared', 'reclining', 'beetle', 'bit', 'a  pitcher', 'indoor', 'reading', 'tabasco sauce', 'flying high', 'for playing', 'parted', 'looking food', 'cubed', 'bundt', 'residential', 'trees', 'minute', 'unrippen', 'leafy', 'laying', 'spiky', 'floating', 'behind', 'tomato', 'white apartments', 'shiny', \"baby's breath\", 'four', 'porcelain', 'personal', 'glazed', 'stir fried', 'rolled', 'unripe', 'on ground', 'wireless', 'retangular', 'outdoors', 'creamer', 'is visible', 'seafood', 'partially blocked', 'pre-packaged', 'video game systems','turning', 'lush', 'hard shell', 'green glass beer', 'play-fighting', 'animal', 'cocked to right','in collection', 'sitted', 'pickup', 'stuffed', 'together', 'crossing road', 'corona', 'spotted', 'newer', 'octagonal', 'fedora', 'in a cluster', 'small ', 'multi storied', 'turning', 'truck', 'modern', 'raft', 'in forefront', 'dumping', 'stopped', 'bmw', 'roman numeral I', 'tower', 'layered', 'grazing', 'bending down', 'scalloped', 'picked up', 'standing', 'oval', 'plush', 'rodeo drive', 'roman', 'big ben', 'display', 'closed', 'khaki', 'lounging', 'tallest', 'casting', 'reflected', 'looking at biker', 'recliner', 'in motion', 'in a costume', 'empty', 'typing', 'colgate brand', 'folded', 'one way sign', 'messy', 'clapping his hands', 'chekered', \"woman's\", 'plastci', 'elephant', 'knotted', 'healthy', 'tangled', 'passing back of mete', 'having skiing lesson', 'relaxing', 'surfing', 'cruet', 'street light', 'angled', 'hanging out', 'displeased', 'looking camera', 'breakfast', 'airplane shaped', 'long sleeve', 'mans', 'lush', 'hard shell', 'green glass beer', 'play-fighting', 'animal', 'cocked to right','holder', 'few', 'snowy', 'overturned','in row', 'for sale', 'part', 'horse', 'rectangular', 'an appaloosa', 'warning', 'city', 'smiling', 'on its side', 'serene', '31', 'wicker', 'round', 'brick wall ', 'looking right', 'baked', 'kicking', 'approaching', 'darker', 'sturdy', 'circle', 'hairy', 'larger', 'black marked', 'eight-sided', 'bleacher', 'abundant', 'being held', 'tea', 'tied up', 'directional', 'umbrella', 'antique', 'oregon city', 'focused', 'clay', 'flower', 'faux', 'palm', 'bare', 'grounded', 'bunched', 'industrial', 'yelling', 'shining', 'green beer', 'Large ', 'missing', 'foliage', 'rectangle', 'building', 'head down', 'cool', 'glass', 'blooming','horizon', 'of glass', 'looking down', 'gypsy cob', 'safety', 'delicious', 'silk', 'diverted bus', 'skating', 'running', 'photographing', 'positioned', 'dirty', 'checkered', 'painted', 'decorative', 'taller', 'reflecting', 'mesh', 'stool', 'floral', 'lying', 'reclined', 'balancing', 'in corner', 'half-empty', 'anchored', 'patterned', 'low', 'male', 'red baron', 'above', 'color', 'curved', 'working', 'dome', 'landing', 'bending over', 'blinded', 'smeared', 'tiny', 'rocking', 'vintage style', 'frontview', 'pitching', 'blurry', 'nice', 'scuffed', 'Sanssouci', 'sesame', 'two way stop', 'zebu-type', 'luggage', 'crocheted', 'rustic', 'long stemmed', 'wide', 'swimming', 'on top head', 'facing backwards', 'sitting up', 'two story', 'floor', 'u.s. flag', 'model', 'chevrolet', 'retriever', 'lined up', 'opened up', 'gra', 'rotting', 'corduroy', 'slices', 'frying', 'iron', 'rusted', 'tall.', 'store sign','shirtless', 'traffic', 'fishing', 'bigger', 'pictured', 'ALL WAY','very tall', '89', 'in captivity', 'hawaiian print', 'lively', 'loosened', 'lengthy','four door', 'aged', 'wearing green', 'looking', 'older', 'driving', 'jelly', 'stripped', 'collie', 'for road', 'front has', 'doubledecker', 'crouching', 'on top', 'speckled', 'plentiful', 'gre', 'ventilated', 't shirt', 'elegant', 'very clean', 'up', 'mirror image', 'wispy', 'lobster', 'solid', 'cloth', 'fancy footed', 'indoors', 'behind man', 'splashing', '6', 'granny smith', 'huge', 'on left side', 'peanutbutter', 'welcoming', 'blocking', 'numerous', 'tennis shirt', 'brow', 'long-sleeve', 'happy', 'present', 'orange traffic ', 'narrow', 'mother', 'in middle', 'high', 'discover', 'boxy', 'no parking', 'spinach', 'dry', 'a pinto', 'vehicle', 'grizzly', 'long sleeved', '4', 'nearby', 'iced', 'in sand', 'short', 'square', 'tile', 'filming', 'powdered', 'hot sauce', 'deep', 'burnt', 'with glass pane', 'sleeveless', 'ocean', 'ruined', 'bath', 'hollywood', 'blurred', 'skiing', 'diamond', 'with mother', 'adule', 'refrigerator ', 'muliple storied', 'gripping', 'resting', 'short sleeved', 'young', 'founders den', 'in sky', 'baseball', 'whole', 'rolling']\n",
    "for c in range(len(notColor)):\n",
    "    notColor[c] = notColor[c].lower().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load questions and answers\n",
    "file = open(\"question_answers.json\")\n",
    "qa = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load objects\n",
    "import ujson\n",
    "file = open(\"objects.json\")\n",
    "objs = ujson.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load objects\n",
    "file = open(\"attributes.json\")\n",
    "attrb = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbal[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrb[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse():\n",
    "    length = len(qa)\n",
    "    for img in range(length):\n",
    "        for q in qa[img]['qas']: \n",
    "            quest = q['question']\n",
    "            parsed = parser.raw_parse(quest)\n",
    "            parsedString = list(parsed)[0].__str__()\n",
    "            q['parsed'] = parsedString\n",
    "            #q['tree'] = parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasVerbal():\n",
    "    length = len(qa)\n",
    "    img = 0\n",
    "    while img < len(qa):\n",
    "        q = 0\n",
    "        while q < len(qa[img]['qas']): \n",
    "            parsed = qa[img]['qas'][q]['parsed']\n",
    "                    \n",
    "            # further prune out unambiguous questions\n",
    "            if \"(NN\" in parsed and \"(VB\" in parsed and \"(PP \" in parsed:\n",
    "                nounI = parsed.index(\"(NN\")\n",
    "                #print(qa[img]['qas'][q]['question'])\n",
    "                #print(parsed)\n",
    "                # not main noun\n",
    "                if parsed.index(\"(NN\") < parsed.index(\"(PP \"):\n",
    "                    if \"does\" not in parsed:\n",
    "                        try:\n",
    "                            nounI = parsed.index(\"(NN\", nounI+1) # index of main noun\n",
    "                        except:\n",
    "                            nounI = parsed.index(\"(NN\")   \n",
    "                nounF = parsed.index(\")\", nounI)\n",
    "                nounB = parsed.index(\" \", nounI)\n",
    "                noun = parsed[nounB+1:nounF]\n",
    "                if noun not in duplicates[img]['names']: # if nonambiguous\n",
    "                    qa[img]['qas'].pop(q)\n",
    "                    q -= 1\n",
    "                else:\n",
    "                    parsed = parsed.replace(\"(PP (IN of)\", \"\").replace(\"(PP (IN like)\", \"\")\n",
    "                    if not (\"(PP \" in parsed and nounB+1 < parsed.index(\"(PP \")):\n",
    "                        qa[img]['qas'].pop(q)\n",
    "                        q -= 1\n",
    "                    elif parsed.rindex(\"(\", 0, parsed.rindex(\"(\",0, parsed.rindex(\"(\"))) != parsed.index(\"(PP \"):\n",
    "                        qa[img]['qas'][q]['q_objects'] = []\n",
    "                        indexOfDuplicate = duplicates[img]['names'].index(noun)\n",
    "                        synset = duplicates[img]['objs'][indexOfDuplicate]['synsets'][0]\n",
    "                        for i in duplicates[img]['objs']:\n",
    "                            if i['synsets'][0] == synset:\n",
    "                                qa[img]['qas'][q]['q_objects'].append(i)\n",
    "                    else:\n",
    "                        qa[img]['qas'].pop(q)\n",
    "                        q -= 1\n",
    "                        \n",
    "            else:\n",
    "                qa[img]['qas'].pop(q)\n",
    "                q -= 1\n",
    "            q += 1\n",
    "        if len(qa[img]['qas']) == 0:\n",
    "            qa.pop(img)\n",
    "            duplicates.pop(img)\n",
    "            attrb.pop(img)\n",
    "            img -= 1\n",
    "        img += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Repeated Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbalQs = []\n",
    "duplicates = []\n",
    "length = len(objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in objs: # for each image\n",
    "    imgID = i['image_id'] # ID of this image\n",
    "    #count += 1\n",
    "    #if count > 1:\n",
    "     #   break\n",
    "    #print(count/length) # print progress\n",
    "    \n",
    "    objInstances = []\n",
    "    objINames = []\n",
    "    objSet = set()\n",
    "    dupObjects = []\n",
    "    dupNames = []\n",
    "    for o in i['objects']: # for each object\n",
    "        for s in o['synsets']: # for each synset\n",
    "            if s in objInstances:\n",
    "                i = objInstances.index(s)\n",
    "                dupObjects.append(objINames[i])\n",
    "                objInstances.pop(i)\n",
    "                dupNames += objINames[i]['names']\n",
    "                objINames.pop(i)\n",
    "                \n",
    "                dupObjects.append(o)\n",
    "                dupNames += o['names']\n",
    "            elif s in objSet: # if synset is duplicate\n",
    "                dupObjects.append(o)\n",
    "                dupNames += o['names']\n",
    "            else: # if synset not duplicate\n",
    "                objInstances.append(s)\n",
    "                objINames.append(o)\n",
    "                objSet.add(s)\n",
    "    duplicates.append({'id': imgID, 'objs': dupObjects, 'names': dupNames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(objs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Ambiguous Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count = 0\n",
    "img = 0\n",
    "while img < len(duplicates):\n",
    "    if len(duplicates[img]['objs']) > 0:\n",
    "        q = 0\n",
    "        while q < len(qa[img]['qas']): \n",
    "            quest = qa[img]['qas'][q]['question']\n",
    "            ambiguous = False\n",
    "            for w in quest.split():\n",
    "                if w in duplicates[img]['names']: # if this question is ambiguous\n",
    "                    ambiguous = True\n",
    "                    #count += 1\n",
    "                    #print(count)\n",
    "                    break\n",
    "            if not ambiguous: # remove non ambiguous questions for this image\n",
    "                qa[img]['qas'].pop(q)\n",
    "                q -= 1\n",
    "            q += 1\n",
    "    else:\n",
    "        duplicates.pop(img)\n",
    "        attrb.pop(img)\n",
    "        qa.pop(img)\n",
    "        img -= 1\n",
    "    img += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up parser from Stanford\n",
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "parser = CoreNLPParser(url='http://localhost:9000')\n",
    "#parse()\n",
    "#hasVerbal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(parser.raw_parse(\"What color is the man on the right?\"))[0].__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "parse()\n",
    "qaParsed = copy.deepcopy(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "qaFile = open('parsed', 'ab') \n",
    "\n",
    "# source, destination \n",
    "pickle.dump(qa, qaFile)                      \n",
    "qaFile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qafile = open('parsed', 'rb')      \n",
    "qa = pickle.load(qafile) \n",
    "qafile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasVerbal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_regions(imgID, objects):\n",
    "    image = vg.get_image_data(id=imgID)\n",
    "    response = requests.get(image.url)\n",
    "    img = PIL_Image.open(BytesIO(response.content))\n",
    "    plt.imshow(img)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    ax = plt.gca()\n",
    "    for o in objects:\n",
    "        ax.add_patch(Rectangle((o['x'], o['y']),\n",
    "                                o['w'],\n",
    "                                o['h'],\n",
    "                                fill=False,\n",
    "                                edgecolor='red',\n",
    "                                linewidth=3))\n",
    "    #ax.text(region.x, region.y, region.phrase, style='italic', bbox={'facecolor':'white', 'alpha':0.7, 'pad':10})\n",
    "    plt.tick_params(labelbottom='off', labelleft='off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_points(imgID, points):\n",
    "    image = vg.get_image_data(id=imgID)\n",
    "    response = requests.get(image.url)\n",
    "    img = PIL_Image.open(BytesIO(response.content))\n",
    "    plt.imshow(img)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    ax = plt.gca()\n",
    "    for o in points:\n",
    "        ax.plot(o['x'],o['y'], 'ro') \n",
    "    #ax.text(region.x, region.y, region.phrase, style='italic', bbox={'facecolor':'white', 'alpha':0.7, 'pad':10})\n",
    "    plt.tick_params(labelbottom='off', labelleft='off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrb[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "verbalQ = copy.deepcopy(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = copy.deepcopy(verbal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(qa):\n",
    "    q = 0\n",
    "    while q < len(qa[i]['qas']):\n",
    "        o_id = []\n",
    "        for o in qa[i]['qas'][q]['q_objects']:\n",
    "            o_id.append(o['object_id'])\n",
    "            \n",
    "        attr = set()\n",
    "        countA = 0\n",
    "        # check for actually non-ambiguuous questions\n",
    "        for a in attrb[i]['attributes']:\n",
    "            if a['object_id'] in o_id and 'attributes' in a:\n",
    "                attr.add(a['attributes'][0])\n",
    "                countA += 1\n",
    "        print(attr)\n",
    "        if len(attr) == 1 and countA > 1:\n",
    "            qa[i]['qas'].pop(q) # not ambiguous question\n",
    "            q -= 1\n",
    "        q += 1\n",
    "    if len(qa[i]['qas']) == 0:\n",
    "        qa.pop(i)\n",
    "        attrb.pop(i)\n",
    "        i -= 1\n",
    "    i += 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrb[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in qa:\n",
    "    imgId = i['id']\n",
    "    #print(imgID)\n",
    "    for q in i['qas']:\n",
    "        print(q['question'])\n",
    "        #print(q['parsed'])\n",
    "        visualize_regions(imgId, q['q_objects'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"how many\" questions\n",
    "i = 0\n",
    "while i < len(qa):\n",
    "    q = 0\n",
    "    while q < len(qa[i]['qas']):\n",
    "        if \"How many\" in qa[i]['qas'][q]['question']:\n",
    "            qa[i]['qas'].pop(q)\n",
    "            q -= 1\n",
    "        q += 1\n",
    "    if len(qa[i]['qas']) == 0:\n",
    "        qa.pop(i)\n",
    "        attrb.pop(i)\n",
    "        i -= 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to new json file\n",
    "with open(\"VisualGenomeVerbal.json\", \"w\") as outfile: \n",
    "    json.dump(verbalQ, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrbV = copy.deepcopy(attrb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load questions and answers\n",
    "import ujson\n",
    "file = open(\"VisualGenomeVerbal.json\")\n",
    "verbalQ = ujson.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in verbalQ:\n",
    "    for q in i['qas']:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "spatialQ = copy.deepcopy(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in spatialQ:\n",
    "    for q in i['qas']:\n",
    "        parsed = q['parsed']\n",
    "        nounI = parsed.index(\"(NN\")\n",
    "        # not main noun\n",
    "        if parsed.index(\"(NN\") < parsed.index(\"(PP \"):\n",
    "            if \"does\" not in parsed:\n",
    "                try:\n",
    "                    nounI = parsed.index(\"(NN\", nounI+1) # index of main noun\n",
    "                except:\n",
    "                    nounI = parsed.index(\"(NN\")   \n",
    "        nounF = parsed.index(\")\", nounI)\n",
    "        nounB = parsed.index(\" \", nounI)\n",
    "        noun = parsed[nounB+1:nounF]\n",
    "        #print(q['question'])\n",
    "        if \"the \" + noun in q['question']:\n",
    "            subject = q['question'].index(\"the \" + noun)\n",
    "        else:\n",
    "            subject = q['question'].index(noun)\n",
    "        q['question'] = q['question'][0: subject] + \"this \" + noun\n",
    "        verbI = parsed.rindex(\"(\")\n",
    "        if parsed[verbI:verbI+3] == \"(VB\":\n",
    "            verbF = parsed.index(\")\", verbI)\n",
    "            verbB = parsed.index(\" \", verbI)\n",
    "            verb = parsed[verbB+1:verbF]\n",
    "            q['question'] += \" \" + verb\n",
    "        q['question'] += \"?\"\n",
    "        print(q['question'])\n",
    "        #if noun not in duplicates[img]['names']: # i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrb = copy.deepcopy(attrbV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(spatialQ):\n",
    "    q = 0\n",
    "    while q < len(spatialQ[i]['qas']):\n",
    "        \n",
    "        spatialQ[i]['qas'][q]['points'] = []\n",
    "        \n",
    "        o_id = []\n",
    "        for o in spatialQ[i]['qas'][q]['q_objects']:\n",
    "            o_id.append(o['object_id'])\n",
    "            \n",
    "        attr = set()\n",
    "        countA = 0\n",
    "\n",
    "        for a in attrb[i]['attributes']: # for each object for this image\n",
    "            if a['object_id'] in o_id and 'attributes' in a: # if relevant object\n",
    "                print(\"answer: \" + spatialQ[i]['qas'][q]['answer'][0:len(spatialQ[i]['qas'][q]['answer'])-1].lower())\n",
    "                print(a['attributes'])\n",
    "                if spatialQ[i]['qas'][q]['answer'][0:len(spatialQ[i]['qas'][q]['answer'])-1].lower() in a['attributes']: # if this is the answer object\n",
    "                    spatialQ[i]['qas'][q]['points'].append({'x': int(a['x'] + a['w'] / 2), 'y': int(a['y'] + a['h'] / 2), 'answer': spatialQ[i]['qas'][q]['answer']})\n",
    "        if len(spatialQ[i]['qas'][q]['points']) == 0:\n",
    "            spatialQ[i]['qas'].pop(q)\n",
    "            verbalQ[i]['qas'].pop(q)\n",
    "            q -= 1\n",
    "        q += 1\n",
    "        \n",
    "    if len(spatialQ[i]['qas']) == 0:\n",
    "        spatialQ.pop(i)\n",
    "        attrb.pop(i)\n",
    "        verbalQ.pop(i)\n",
    "        i -= 1\n",
    "    i += 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in verbalQ:\n",
    "    for q in i['qas']:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatialQ[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to new json file\n",
    "with open(\"VisualGenomeSpatial.json\", \"w\") as outfile: \n",
    "    json.dump(spatialQ, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Section End\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(verbalQ)):\n",
    "    imgId = verbalQ[i]['id']\n",
    "    imgId2 = spatialQ[i]['id']\n",
    "    for q in range(len(verbalQ[i]['qas'])):\n",
    "        print(verbalQ[i]['qas'][q]['question'])\n",
    "        #print(verbalQ[i]['qas'][q]['parsed'])\n",
    "        visualize_regions(imgId, verbalQ[i]['qas'][q]['q_objects'])\n",
    "        visualize_points(imgId2, spatialQ[i]['qas'][q]['points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
